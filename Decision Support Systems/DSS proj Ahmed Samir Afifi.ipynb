{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images and features = (675, 200)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from scipy import ndimage \n",
    "from sklearn.cluster import KMeans\n",
    "import imageio\n",
    "\n",
    "################  Image_Partition  ##################################\n",
    "\n",
    "\n",
    "def Image_Partition(img_list):\n",
    "    vectors=[]\n",
    "    patch_x = 64\n",
    "    patch_y = 64\n",
    "    \n",
    "    for filtered_img in img_list:\n",
    "        #count=0\n",
    "        for x in range(0,filtered_img.shape[0]+1 - patch_x, patch_x):\n",
    "            #count2=0\n",
    "            for y in range(0,filtered_img.shape[1]+1 - patch_y, patch_y):\n",
    "                patch = filtered_img[x:x+patch_x,y:y+patch_y]\n",
    "                '''\n",
    "                 vertical_projection\n",
    "                '''\n",
    "                vector = np.sum(patch, axis = 1)\n",
    "                vectors.append(vector)\n",
    "            #    count2+=1\n",
    "           # count+=1\n",
    "            #partition_part.append(window)\n",
    "\n",
    "\n",
    "         #   print(count2)\n",
    "          ##  print(count) \n",
    "       # print(filtered_img.shape[1]+1)\n",
    "    return vectors\n",
    "\n",
    "########################## paper  #################################\n",
    "#print(filtered_img.shape[0])\n",
    "\n",
    "########################  Schmid filters  ############################\n",
    "def Make_filter(kernal_size,tau,sigma):   \n",
    "    hsup=(kernal_size-1)/2\n",
    "    m1 = np.linspace(-hsup, hsup,kernal_size) \n",
    "    m2 = np.linspace(-hsup, hsup,kernal_size)\n",
    "    [x,y]=np.meshgrid(m1,m2)\n",
    "    mul=((x*x)+(y*y))\n",
    "    r= np.sqrt(mul)\n",
    "    f=(np.cos(2*r*(np.pi*tau/sigma))*(np.exp(-(r*r)/(2*sigma*sigma))))\n",
    "    f -= np.mean(f)     \n",
    "    f=f/np.sum(np.abs(f))\n",
    "    #print(f)\n",
    "    return f\n",
    "\n",
    "\n",
    "def Schmid_Filter(training_img):\n",
    "\n",
    "    kernal_size=49        \n",
    "    img_list=[]\n",
    "    for i in range(5):    \n",
    "        if i==0:   \n",
    "            fimg =cv2.filter2D(training_img, cv2.CV_8UC3,Make_filter(kernal_size,2,1)) \n",
    "        elif i==1:  \n",
    "            fimg =cv2.filter2D(training_img, cv2.CV_8UC3,Make_filter(kernal_size,4,2)) \n",
    "        elif i==2:\n",
    "            fimg =cv2.filter2D(training_img, cv2.CV_8UC3,Make_filter(kernal_size,6,2)) \n",
    "        elif i==3:\n",
    "            fimg =cv2.filter2D(training_img, cv2.CV_8UC3,Make_filter(kernal_size,8,2)) \n",
    "        elif i==4:\n",
    "            fimg =cv2.filter2D(training_img, cv2.CV_8UC3,Make_filter(kernal_size,10,2)) \n",
    "           #you can determine the constatnt  \n",
    "           #fimg =ndimage.filters.convolve(img, Make_filter(kernal_size,10,2), mode='constant',cval=0.0) \n",
    "           #mode='same' mean the output keep the same as innput\n",
    "           #fimg =ndimage.filters.convolve(img, Make_filter(kernal_size,10,2), mode='same') \n",
    "        img_list.append(fimg)\n",
    "    return img_list  \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################  Gabor Filtes  ############################\n",
    "\n",
    "\n",
    "#kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, phi, ktype=cv2.CV_32F)\n",
    "def Gabor_Filter(training_img):\n",
    "    img_list=[]\n",
    "    for i in range(4):\n",
    "        if i==0:\n",
    "            kernel = cv2.getGaborKernel((15, 15), 2, 0, 4, .3, 0, ktype=cv2.CV_32F)     \n",
    "            fimg = cv2.filter2D(training_img, cv2.CV_8UC3, kernel)\n",
    "        elif i==1:  \n",
    "            kernel = cv2.getGaborKernel((15, 15), 1, 0, 4, .4, 0, ktype=cv2.CV_32F)     \n",
    "            fimg = cv2.filter2D(training_img, cv2.CV_8UC3, kernel) \n",
    "        elif i==2:\n",
    "            kernel = cv2.getGaborKernel((15, 15), 2, np.pi/2, 8, .3, 0, ktype=cv2.CV_32F)     \n",
    "            fimg = cv2.filter2D(training_img, cv2.CV_8UC3, kernel)\n",
    "        elif i==3:\n",
    "            kernel = cv2.getGaborKernel((15, 15), 1, np.pi/2, 8, .4, 0, ktype=cv2.CV_32F)     \n",
    "            fimg = cv2.filter2D(training_img, cv2.CV_8UC3, kernel)\n",
    "\n",
    "        \n",
    "        img_list.append(fimg)\n",
    "    return img_list  \n",
    "\n",
    "\n",
    "#######################  read dataset and get random two image from each class  ########################## \n",
    "\n",
    "dataset_path= 'EXACT09_CT'\n",
    "\n",
    "list_of_classes_name = os.listdir(dataset_path)\n",
    "\n",
    "#print(dirs)\n",
    "\n",
    "''' \n",
    "#get 2 imgae randome from each class  \n",
    "'''\n",
    "list_training_vectors=[]\n",
    "\n",
    "count_random_images = 2    \n",
    "for class_name in list_of_classes_name:\n",
    "    list_all_images_in_class=os.listdir(dataset_path+'\\\\'+class_name)    \n",
    "    for i in range(count_random_images):\n",
    "        image_name = random.choice(list_all_images_in_class)\n",
    "        image_path = os.path.join(dataset_path,class_name,image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "#        assert not isinstance(im,type(None)), 'image not found'\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "        gabor_output=Gabor_Filter(image)\n",
    "        schmid_output=Schmid_Filter(image)\n",
    "        vectors=Image_Partition(gabor_output+schmid_output)\n",
    "        #print(image.shape)\n",
    "        list_training_vectors.append(vectors)\n",
    "\n",
    "\n",
    "\n",
    "all_training_vectors=np.array(list_training_vectors) \n",
    "\n",
    "all_training_vectors=all_training_vectors.reshape((all_training_vectors.shape[0]*all_training_vectors.shape[1]),all_training_vectors.shape[2])\n",
    "\n",
    "\n",
    "'''\n",
    "#third step\n",
    "#learn the dictionary\n",
    "'''\n",
    "#k-means++  = selects initial cluster centers for k-mean clustering in a smart way to speed up\n",
    "#n_init = Number of time the k-means algorithm will be run with different centroid seeds. \n",
    "#The final results will be the best output of n_init consecutive runs in terms of inertia.\n",
    "\n",
    "# random_state Determines random number generation for centroid initialization\n",
    "\n",
    "### The default values are n_init=10 and max_iter=300. \n",
    "## This means the initial centroids will be chosen 10 times, \n",
    "## and each run will use up to 300 iterations. \n",
    "## The best out of those 10 runs will be the final result.\n",
    "n_dic=200\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_dic, init='k-means++' ,max_iter=300, n_init=10, random_state=None)\n",
    "try:\n",
    "    kmeans.fit(all_training_vectors)\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "convert all images in dataset into patchs then into vectors\n",
    "'''\n",
    "\n",
    "list_images_path=[]\n",
    "list_vectors=[]\n",
    "num_of_img=0\n",
    "\n",
    "\n",
    "\n",
    "for class_name in list_of_classes_name:\n",
    "    list_all_images_in_class=os.listdir(dataset_path+'\\\\'+class_name) \n",
    "    for i in list_all_images_in_class:\n",
    "        num_of_img +=1\n",
    "        image_path = os.path.join(dataset_path,class_name,i)\n",
    "        list_images_path.append(image_path)\n",
    "        image = cv2.imread(image_path)\n",
    "       # assert not isinstance(im,type(None)), 'image not found'\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  \n",
    "        gabor_output=Gabor_Filter(image)\n",
    "        schmid_output=Schmid_Filter(image)  \n",
    "        vectors=Image_Partition(gabor_output+schmid_output)\n",
    "\n",
    "        list_vectors.append(vectors)\n",
    "\n",
    "\n",
    "    \n",
    "all_dataset_vectors=np.array(list_vectors) \n",
    "   \n",
    "all_dataset_vectors = all_dataset_vectors.reshape((all_dataset_vectors.shape[0]*all_dataset_vectors.shape[1]),all_dataset_vectors.shape[2])\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "  #four step\n",
    "  #obtain the histogram from bag of features(BoVW)\n",
    "  #compute features for each images\n",
    "'''\n",
    "\n",
    "list_histogram_of_each_image_in_dataset =[]\n",
    "classification=np.arange(200)\n",
    "for i in range(num_of_img):\n",
    "    #predicting n_patches of an image\n",
    "    #classification array of prediction class for each patch\n",
    "    classification=kmeans.predict(all_dataset_vectors[(i*576): (i*576)+576])\n",
    "    \n",
    "    #computes histogarme and append in the array\n",
    "    ##densitybool, optional If False, the result will contain the number of samples in each bin. \n",
    "    #If True, the result is the value of the probability density function at the bin\n",
    "    image_histogram,_=np.histogram(classification, bins=range(n_dic+1),density=True)\n",
    "    #np.histogram return array of image_histogram and bins_edges of (length(hist)+1) \n",
    "    list_histogram_of_each_image_in_dataset.append(image_histogram)\n",
    "    \n",
    "list_histogram_of_each_image_in_dataset = np.array(list_histogram_of_each_image_in_dataset)\n",
    "print('Number of images and features =',list_histogram_of_each_image_in_dataset.shape)  \n",
    "\n",
    "'''\n",
    "calculate the ARP\n",
    "Query part\n",
    "'''\n",
    "\n",
    "final_ARP=[]\n",
    "ARP_of_class=[]\n",
    "\n",
    "def hist_match(query_hist,image_hist):\n",
    "    result=0\n",
    "    for i in range(query_hist.size):\n",
    "        if query_hist[i]<=image_hist[i]:\n",
    "            result=result+query_hist[i]\n",
    "        else:\n",
    "            result=result+image_hist[i] \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "from tkinter.filedialog import askopenfile\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "C:/Users/farag/DSS/EXACT09_CT/2/3133230.jpg\n",
      "9\n",
      "C:/Users/farag/DSS/EXACT09_CT/9/3133454.jpg\n"
     ]
    }
   ],
   "source": [
    "#GUI of Prediction   \n",
    "window = tk.Tk()\n",
    "menu = Menu(window)\n",
    "window.config(menu=menu)\n",
    "filemenu = Menu(menu)\n",
    "menu.add_cascade(label='File', menu=filemenu)\n",
    "filemenu.add_command(label='New')\n",
    "filemenu.add_command(label='Open...')\n",
    "filemenu.add_separator()\n",
    "filemenu.add_command(label='Exit', command=menu.quit)\n",
    "helpmenu = Menu(menu)\n",
    "menu.add_cascade(label='Help', menu=helpmenu)\n",
    "helpmenu.add_command(label='About')\n",
    "\n",
    "ourMessage ='Welcome to our GUI where we classify the Lungs Images'\n",
    "messageVar = Message(window, width=300,fg=\"white\",text = ourMessage)\n",
    "messageVar.config(bg='gray')\n",
    "messageVar.pack( )\n",
    "\n",
    "our ='------------------------------------------------------------ '\n",
    "messageVa = Message(window, width=300,fg=\"white\",text = our)\n",
    "messageVa.config(bg='gray')\n",
    "messageVa.pack( )\n",
    "\n",
    "\n",
    "our ='Ahmed Samir Afifi '\n",
    "messageVa = Message(window, width=300,fg=\"white\",text = our)\n",
    "messageVa.config(bg='gray')\n",
    "messageVa.pack( )\n",
    "\n",
    "our ='Asmaa Shawqy Youins'\n",
    "messageVa = Message(window, width=300,fg=\"white\",text = our)\n",
    "messageVa.config(bg='gray')\n",
    "messageVa.pack( )\n",
    "\n",
    "our ='Aya sherief Elasmar'\n",
    "messageVa = Message(window, width=300,fg=\"white\",text = our)\n",
    "messageVa.config(bg='gray')\n",
    "messageVa.pack( )\n",
    "\n",
    "our ='Hekmat Gmal AbuElnnasr'\n",
    "messageVa = Message(window, width=300,fg=\"white\",text = our)\n",
    "messageVa.config(bg='gray')\n",
    "messageVa.pack( )\n",
    "\n",
    "our ='Youmna Bahaa Eldean'\n",
    "messageVa = Message(window, width=300,fg=\"white\",text = our)\n",
    "messageVa.config(bg='gray')\n",
    "messageVa.pack( )\n",
    "\n",
    "our ='Nada Reda Afifi'\n",
    "messageVa = Message(window, width=300,fg=\"white\",text = our)\n",
    "messageVa.config(bg='gray')\n",
    "messageVa.pack( )\n",
    "\n",
    "\n",
    "# Set window title\n",
    "window.configure(background='gray')\n",
    "window.title('This Form to Classify the Images of Lungs Tumor')\n",
    "window.geometry('900x300')\n",
    "\n",
    "window.resizable(False, False)\n",
    "\n",
    "txtbox= tk.Entry(window,width=100)\n",
    "txtbox= tk.Entry(window,width=50)\n",
    "txtbox.pack()\n",
    "\n",
    "btn = tk.Button(window,text=\"Classify\",width=20,command = lambda:upload_file())\n",
    "btn.pack()\n",
    "\n",
    "\n",
    "\n",
    "def upload_file():\n",
    "    f_types = [('Jpg Files', '*.jpg'),\n",
    "               ('PNG Files', '*.png')]   # type of files to select\n",
    "    filename = tk.filedialog.askopenfilename(multiple=True, filetypes=f_types)\n",
    "    txtbox.insert(0,filename)\n",
    "    class_name = str(list(filename))[-16:-13].replace(\"/\",\"\")\n",
    "    print(class_name)\n",
    "    list_all_images_in_class = os.listdir(dataset_path+'/'+class_name)\n",
    "\n",
    "    image_path = str(list(filename))[2:-2]\n",
    "    print(image_path)\n",
    "    average_precision=0\n",
    "    list_all_images_in_class=os.listdir(dataset_path+'/'+class_name)\n",
    "    query_image = cv2.imread(image_path)\n",
    "   # assert not isinstance(im,type(None)), 'image not found'\n",
    "    query_image = cv2.cvtColor(query_image, cv2.COLOR_BGR2GRAY)  \n",
    "    gabor_output=Gabor_Filter(query_image)\n",
    "    schmid_output=Schmid_Filter(query_image)\n",
    "    #get the features vectors of the query \n",
    "    query_vectors=Image_Partition(gabor_output+schmid_output)\n",
    "    #convert list to array\n",
    "    query_vectors = np.array(query_vectors)\n",
    "    query_classify=kmeans.predict(query_vectors)\n",
    "    #get the histograam of the query\n",
    "    query_histogram,_=np.histogram(query_classify,bins=range(n_dic+1),density=True)\n",
    "\n",
    "   #claculte the amount similarity between query histogam and all images histogram\n",
    "    #and append in list_amount_similarity the result of the similarity for each image and the path of this image \n",
    "    list_amount_similarity = []\n",
    "    for x in range(num_of_img):    \n",
    "        similarity_result=hist_match(list_histogram_of_each_image_in_dataset[x],query_histogram)\n",
    "        list_amount_similarity.append((similarity_result,str(list_images_path[x])))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    total_image_retrieved=10\n",
    "    #ordered the amount of similarity in the list fom small to larg and take the \n",
    "    #number of top image you want to retreive\n",
    "    top_image_retrieved = sorted(list_amount_similarity,reverse=True)[:total_image_retrieved]\n",
    "\n",
    "\n",
    "\n",
    "    #imgs =[]\n",
    "    path_retrieved_image=[]\n",
    "    retrieved_image_class=[]\n",
    "    similarity_result=[]\n",
    "    count =0\n",
    "    #get path of each reterievd image and append to path_retrieved_image\n",
    "    #and get claass of this reteived image and append to retrieved_image_class\n",
    "    for similarity_amount, image_path in top_image_retrieved:\n",
    "        similarity_result.append(similarity_amount) \n",
    "        path_retrieved_image.append(image_path)\n",
    "        class_path=os.path.dirname(image_path)\n",
    "        retrieved_image_class.append(os.path.basename(class_path)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.subplot(441);plt.imshow(query_image)\n",
    "    plt.title('Query');plt.axis('off')\n",
    "\n",
    "    retrieved_image =[]\n",
    "    relevant_images=0 \n",
    "\n",
    "    #calculate the pecision for each query \n",
    "    #and then add the pecision to the average_precision\n",
    "    if int(class_name)==1: \n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.2f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==1:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision      \n",
    "\n",
    "    elif int(class_name) ==2:\n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==2:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision    \n",
    "\n",
    "\n",
    "    elif int(class_name) ==3: \n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "\n",
    "            if int(retrieved_image_class[i])==3:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision     \n",
    "\n",
    "    elif int(class_name) ==4: \n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==4:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision         \n",
    "\n",
    "    elif int(class_name) ==5: \n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==5:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision     \n",
    "\n",
    "    elif int(class_name) ==6: \n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==6:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision        \n",
    "\n",
    "    elif int(class_name) ==7: \n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==7:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision         \n",
    "\n",
    "    elif int(class_name) ==8:\n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==8:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision         \n",
    "\n",
    "    elif int(class_name) ==9: \n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==9:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision         \n",
    "\n",
    "    elif int(class_name) ==10:\n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==10:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision        \n",
    "\n",
    "    elif int(class_name) ==11: \n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==11:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision       \n",
    "\n",
    "    elif int(class_name) ==12: \n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==12:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision        \n",
    "\n",
    "    elif int(class_name) ==13: \n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==13:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision        \n",
    "\n",
    "    elif int(class_name) ==14: \n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==14:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision      \n",
    "\n",
    "    elif int(class_name) ==15: \n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==15:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision       \n",
    "\n",
    "    elif int(class_name) ==16:\n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==16:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision        \n",
    "\n",
    "\n",
    "    elif int(class_name) ==17: \n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==17:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision        \n",
    "\n",
    "    elif int(class_name)==18: \n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==18:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision       \n",
    "\n",
    "    elif int(class_name) ==19:\n",
    "        for i in range(total_image_retrieved):\n",
    "            retrieved_image.append(imageio.imread(path_retrieved_image[i]))\n",
    "            plt.subplot(4,4,i+2); plt.imshow(retrieved_image[i])\n",
    "            plt.title('%d, %.4f,%d' % (i,similarity_result[i],int(retrieved_image_class[i])));plt.axis('off')  \n",
    "\n",
    "            if int(retrieved_image_class[i])==19:\n",
    "                relevant_images +=1\n",
    "        precision=relevant_images/total_image_retrieved\n",
    "        average_precision+=precision    \n",
    "\n",
    "\n",
    "    number_of_images_in_class=len(list_all_images_in_class)\n",
    "    #use the average_precision for each class to calculate ARP for each class and append to ARP_of_class\n",
    "    ARP_of_class.append((100/number_of_images_in_class)*average_precision)\n",
    "\n",
    "    \n",
    "\n",
    "window.mainloop()  # Keep the window open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
